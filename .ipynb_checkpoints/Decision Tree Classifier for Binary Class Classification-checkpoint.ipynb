{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier (CART) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_table(path)\n",
    "    dataset = df.values.tolist()\n",
    "\n",
    "    data = []\n",
    "    for row in dataset:\n",
    "        data.append([float(i) for i in row[0].split(\",\")])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, train_size):\n",
    "    train, test = [], []\n",
    "    \n",
    "    for i, row in enumerate(dataset):\n",
    "        if i < len(dataset) * train_size:\n",
    "            train.append(row)\n",
    "        else:\n",
    "            test.append(row)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data, index, value):\n",
    "    left, right = [], []\n",
    "    \n",
    "    for row in data:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "            \n",
    "    return [left, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(groups):\n",
    "    # load left and right groups\n",
    "    left, right = groups[0], groups[1] \n",
    "    \n",
    "    # Sample size of each groups for probability calculation\n",
    "    num_left_samples = float(len(left))\n",
    "    num_right_samples = float(len(right))\n",
    "    num_total_samples = num_left_samples + num_right_samples\n",
    "    \n",
    "    # Each class samples in each groups\n",
    "    num_left_class_0 = [row[-1] for row in left].count(0) # Class 0 samples in left\n",
    "    num_left_class_1 = [row[-1] for row in left].count(1) # Class 1 samples in left\n",
    "    num_right_class_0 = [row[-1] for row in right].count(0) # Class 0 samples in right\n",
    "    num_right_class_1 = [row[-1] for row in right].count(1) # Class 1 samples in right\n",
    "    \n",
    "    # Probability scores\n",
    "    left_class_0_prob, left_class_1_prob, right_class_0_prob, right_class_1_prob = 0.0, 0.0, 0.0, 0.0\n",
    "    left_total_score, right_total_score = 0.0, 0.0\n",
    "    \n",
    "    # check if the left samples are empty\n",
    "    if not num_left_samples:\n",
    "        pass\n",
    "    else:\n",
    "        left_class_0_prob = num_left_class_0 / num_left_samples\n",
    "        left_class_1_prob = num_left_class_1 / num_left_samples\n",
    "        left_total_score = left_class_0_prob**2 + left_class_1_prob**2 # Take the total square probabilities\n",
    "    \n",
    "    # Check if the right samples are empty\n",
    "    if not num_right_samples:\n",
    "        pass\n",
    "    else:\n",
    "        right_class_0_prob = num_right_class_0 / num_right_samples\n",
    "        right_class_1_prob = num_right_class_1 / num_right_samples\n",
    "        right_total_score = right_class_0_prob**2 + right_class_1_prob**2 # Take the total square probabilities\n",
    "    \n",
    "    # Calculate Gini score for each groups\n",
    "    left_gini_score = (1 - left_total_score)*num_left_samples / num_total_samples\n",
    "    right_gini_score = (1 - right_total_score)*num_right_samples / num_total_samples\n",
    "    \n",
    "    return left_gini_score + right_gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(train, lowest_gini=100.0, gini_score=0.0):\n",
    "    \n",
    "    # Looping through all the values in each column except class column\n",
    "    for col in range(len(train[0])-1):\n",
    "        for row in train:\n",
    "            groups = test_split(train, col, row[col]) # split into groups based on each value\n",
    "            gini_score = gini(groups) # Calc Gini score\n",
    "            \n",
    "            # Check if the lowest gini is found\n",
    "            if gini_score < lowest_gini:\n",
    "                lowest_gini = gini_score # Find the lowest Gini\n",
    "                best_index, best_value, best_group = col, row[col], groups # Take the best split based values\n",
    "                \n",
    "    return {\"index\": best_index, \"val\": best_value, \"gini\": lowest_gini, \"sub-tree\": best_group}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_node(group):\n",
    "    class_vals = [row[-1] for row in group] # Take the class values in the group\n",
    "    return max(set(class_vals), key=class_vals.count) # Return the most frequent class in this group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(node, max_depth, min_samples, depth=0):\n",
    "    \n",
    "    # Take the sub-tree from the passing node\n",
    "    left, right = node[\"sub-tree\"]\n",
    "    \n",
    "    # Remove the sub_tree since did not decide yet further split or make it as a leaf node \n",
    "    del(node[\"sub-tree\"])\n",
    "    \n",
    "    # Check if the left or right groups are empty if so they become leaf node\n",
    "    if not left or not right:\n",
    "        node[\"left\"] = node[\"right\"] = leaf_node(left+right) # passing all data since one group is empty\n",
    "        return\n",
    "    \n",
    "    # check if the max_depth is reached, if so left and right become leaf node\n",
    "    # No more further spliting is needed\n",
    "    if depth >= max_depth:\n",
    "        node[\"left\"] = leaf_node(left)\n",
    "        node[\"right\"] = leaf_node(right)\n",
    "        return\n",
    "        \n",
    "    # checking min_samples before split, if less then no spilt needed and become leaf node\n",
    "    # otherwise further splitting is required\n",
    "    if len(left) <= min_samples:\n",
    "        node[\"left\"] = leaf_node(left)\n",
    "        return\n",
    "    else:\n",
    "        # Adding a sub-tree to the left\n",
    "        node[\"left\"] = best_split(left)\n",
    "        # Build the left sub-tree\n",
    "        build_tree(node[\"left\"], max_depth, min_samples, depth+1)\n",
    "        \n",
    "    # checking min_samples before split, if less then no spilt needed and become leaf node\n",
    "    # otherwise further splitting is required\n",
    "    if len(right) <= min_samples:\n",
    "        node[\"right\"] = leaf_node(right)\n",
    "        return\n",
    "    else:\n",
    "        # Adding a sub-tree to the left\n",
    "        node[\"right\"] = best_split(right)\n",
    "        # Build the left sub-tree\n",
    "        build_tree(node[\"right\"], max_depth, min_samples, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train, max_depth, min_samples, depth):\n",
    "    # Find the root node first\n",
    "    root_node = best_split(train)\n",
    "    \n",
    "    # Passing root node to build the tree\n",
    "    build_tree(root_node, max_depth, min_samples, depth)\n",
    "    \n",
    "    return root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree):\n",
    "    # Check if the passing node is a tree if so recurssivly printing, otherwise print the class label\n",
    "    if isinstance(tree, dict):\n",
    "        print(\"column {} < {} | Gini: {}\".format(tree[\"index\"], tree[\"val\"], tree[\"gini\"]))\n",
    "        print_tree(tree[\"left\"])\n",
    "        print_tree(tree[\"right\"])\n",
    "    else:\n",
    "        print(\"Class: {}\".format(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, test, prediction=[], depth=0):\n",
    "    # checking each test data\n",
    "    if depth < len(test):\n",
    "        if test[depth][tree.get('index')] < tree.get(\"val\"): # Checking each record against decision criteria\n",
    "            if isinstance(tree[\"left\"], dict): \n",
    "                predict(tree[\"left\"], test, prediction, depth) # If the node is a sub-tree then recursively go deeper\n",
    "            else:            \n",
    "                prediction.append(tree.get(\"left\")) # comes to a leaf node so append the predicted class\n",
    "                predict(tree, test, prediction, depth+1)\n",
    "        else:\n",
    "            if isinstance(tree[\"right\"], dict):\n",
    "                predict(tree[\"right\"], test, prediction, depth)\n",
    "            else:\n",
    "                prediction.append(tree.get(\"right\"))\n",
    "                predict(tree, test, prediction, depth+1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(actual, predicted):\n",
    "    # Calculate the error\n",
    "    err = [abs(i-j) for i,j in zip(actual, predicted)]\n",
    "    return str((1.0 - float(sum(err)) / len(err))*100)+\" %\" # 1 - error_rate gives the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "dataset = load_data(\"data_banknote_authentication.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test split\n",
    "train, test = train_test_split(dataset, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the dataset into the model\n",
    "tree = fit(train, max_depth=5, min_samples=1, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test samples\n",
    "prediction = predict(tree, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100.0 %'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class = [row[-1] for row in test]\n",
    "# Calculate the accuracy\n",
    "accuracy(actual_class, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
